#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–è®­ç»ƒè°ƒåº¦å™¨

ä¸“ä¸ºç”Ÿäº§ç¯å¢ƒè®¾è®¡çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œç‰¹ç‚¹ï¼š
- ä¸éœ€è¦ç‰ˆæœ¬æ§åˆ¶ï¼Œåªä¿ç•™æ¯æ—¥æœ€æ–°æ¨¡å‹
- å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œæ— éœ€äººå·¥å¹²é¢„
- åŸºäºç°æœ‰è®­ç»ƒç®¡é“ï¼Œç›´æ¥è°ƒç”¨scripts/run_pipeline.py
- æ™ºèƒ½è®­ç»ƒå†³ç­–å’Œç›‘æ§
"""

import os
import sys
import logging
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from scripts.run_pipeline import train_all_cities, show_model_status, cleanup_old_models
from ml.src.control import get_supported_cities
from ml.src.data_loader import load_data_from_mysql


@dataclass
class SimpleTrainingResult:
    """è®­ç»ƒç»“æœ"""
    timestamp: str
    total_cities: int
    successful_cities: int
    failed_cities: int
    skipped_cities: int
    execution_time: float
    successful_city_list: List[str]
    failed_city_list: List[str]
    skipped_city_list: List[str]


class SimpleAutoTrainingScheduler:
    """è‡ªåŠ¨åŒ–è®­ç»ƒè°ƒåº¦å™¨"""
    
    def __init__(self, log_dir: str = None):
        """
        åˆå§‹åŒ–è®­ç»ƒè°ƒåº¦å™¨
        
        Args:
            log_dir (str): æ—¥å¿—ç›®å½•ï¼Œé»˜è®¤ä¸º logs/auto_training
        """
        self.log_dir = log_dir or os.path.join(os.getcwd(), 'logs', 'auto_training')
        self.logger = self._setup_logger()
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('SimpleAutoTrainingScheduler')
        logger.setLevel(logging.INFO)
        
        # é¿å…é‡å¤æ·»åŠ handler
        if logger.handlers:
            return logger
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(self.log_dir, exist_ok=True)
        
        # æ–‡ä»¶handler - æŒ‰æ—¥æœŸå‘½å
        today = datetime.now().strftime('%Y%m%d')
        log_file = os.path.join(self.log_dir, f'auto_training_{today}.log')
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def check_data_freshness(self, days_threshold: int = 3) -> Tuple[List[str], List[str]]:
        """
        æ£€æŸ¥æ•°æ®å¯ç”¨æ€§å’Œè®­ç»ƒéœ€æ±‚ï¼Œç¡®å®šå“ªäº›åŸå¸‚éœ€è¦è®­ç»ƒ
        
        Args:
            days_threshold (int): æ•°æ®å¯ç”¨æ€§é˜ˆå€¼ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤3å¤©å†…æœ‰æ•°æ®å³å¯
            
        Returns:
            Tuple[List[str], List[str]]: (éœ€è¦è®­ç»ƒçš„åŸå¸‚, è·³è¿‡çš„åŸå¸‚)
        """
        cities = get_supported_cities()
        cities_to_train = []
        cities_to_skip = []
        
        # æ•°æ®å¯ç”¨æ€§é˜ˆå€¼ï¼šæœ€è¿‘Nå¤©å†…æœ‰æ•°æ®å³å¯
        data_cutoff_time = datetime.now() - timedelta(days=days_threshold)
        today_str = datetime.now().strftime("%Y%m%d")
        
        for city in cities:
            try:
                # 1. æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»è®­ç»ƒè¿‡æ¨¡å‹
                from scripts.run_pipeline import is_model_trained_today
                if is_model_trained_today(city):
                    cities_to_skip.append(city)
                    self.logger.info(f"{city}: ä»Šæ—¥æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡è®­ç»ƒ")
                    continue
                
                # 2. æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
                df = load_data_from_mysql(city)
                if df.empty:
                    cities_to_skip.append(city)
                    self.logger.warning(f"{city}: æ— å¯ç”¨æ•°æ®")
                    continue
                
                # 3. æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
                if len(df) < 100:
                    cities_to_skip.append(city)
                    self.logger.warning(f"{city}: æ•°æ®é‡ä¸è¶³ ({len(df)}æ¡)")
                    continue
                
                # 4. æ£€æŸ¥æ•°æ®æ˜¯å¦å¤ªé™ˆæ—§ï¼ˆè¶…è¿‡é˜ˆå€¼å¤©æ•°ï¼‰
                latest_time = df['observation_time'].max()
                if latest_time < data_cutoff_time:
                    cities_to_skip.append(city)
                    self.logger.warning(f"{city}: æ•°æ®è¿‡äºé™ˆæ—§ (æœ€æ–°: {latest_time}, é˜ˆå€¼: {days_threshold}å¤©)")
                    continue
                
                # 5. æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥è®­ç»ƒ
                cities_to_train.append(city)
                days_old = (datetime.now() - latest_time).days
                self.logger.info(f"{city}: æ•°æ®æ£€æŸ¥é€šè¿‡ (æœ€æ–°: {latest_time}, {days_old}å¤©å‰, å…±{len(df)}æ¡)")
                
            except Exception as e:
                cities_to_skip.append(city)
                self.logger.error(f"{city}: æ•°æ®æ£€æŸ¥å¤±è´¥ - {str(e)}")
        
        self.logger.info(f"æ•°æ®æ£€æŸ¥å®Œæˆ: éœ€è®­ç»ƒ{len(cities_to_train)}ä¸ªåŸå¸‚, è·³è¿‡{len(cities_to_skip)}ä¸ªåŸå¸‚")
        return cities_to_train, cities_to_skip
    
    def run_daily_training(self) -> SimpleTrainingResult:
        """
        æ‰§è¡Œæ¯æ—¥è‡ªåŠ¨è®­ç»ƒ
        
        Returns:
            SimpleTrainingResult: è®­ç»ƒç»“æœ
        """
        start_time = datetime.now()
        self.logger.info("=" * 60)
        self.logger.info(f"å¼€å§‹æ¯æ—¥è‡ªåŠ¨æ¨¡å‹è®­ç»ƒ - {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("=" * 60)
        
        try:
            # 1. æ˜¾ç¤ºå½“å‰æ¨¡å‹çŠ¶æ€
            self.logger.info("ğŸ“Š å½“å‰æ¨¡å‹çŠ¶æ€:")
            show_model_status()
            
            # 2. æ£€æŸ¥æ•°æ®æ–°é²œåº¦
            self.logger.info("\nğŸ” æ£€æŸ¥æ•°æ®æ–°é²œåº¦...")
            cities_to_train, cities_to_skip = self.check_data_freshness()
            
            if not cities_to_train:
                self.logger.info("æ‰€æœ‰åŸå¸‚éƒ½å·²è·³è¿‡ï¼Œæ— éœ€è®­ç»ƒ")
                end_time = datetime.now()
                return SimpleTrainingResult(
                    timestamp=start_time.isoformat(),
                    total_cities=len(get_supported_cities()),
                    successful_cities=0,
                    failed_cities=0,
                    skipped_cities=len(cities_to_skip),
                    execution_time=(end_time - start_time).total_seconds(),
                    successful_city_list=[],
                    failed_city_list=[],
                    skipped_city_list=cities_to_skip
                )
            
            # 3. æ‰§è¡Œè®­ç»ƒï¼ˆä½¿ç”¨ç°æœ‰çš„train_all_citieså‡½æ•°ï¼‰
            self.logger.info(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {len(cities_to_train)} ä¸ªåŸå¸‚...")
            training_results = train_all_cities()
            
            # 4. è§£æè®­ç»ƒç»“æœ
            successful_cities = training_results.get('successful', [])
            failed_cities = training_results.get('failed', [])
            
            # 5. æ¸…ç†æ—§æ¨¡å‹
            self.logger.info("\nğŸ§¹ æ¸…ç†æ—§æ¨¡å‹æ–‡ä»¶...")
            cleaned_count = cleanup_old_models(days_to_keep=7)
            self.logger.info(f"å·²æ¸…ç† {cleaned_count} ä¸ªæ—§æ¨¡å‹æ–‡ä»¶")
            
            # 6. æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
            self.logger.info("\nğŸ“Š è®­ç»ƒåæ¨¡å‹çŠ¶æ€:")
            show_model_status()
            
            # 7. ç”Ÿæˆç»“æœ
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            result = SimpleTrainingResult(
                timestamp=start_time.isoformat(),
                total_cities=len(get_supported_cities()),
                successful_cities=len(successful_cities),
                failed_cities=len(failed_cities),
                skipped_cities=len(cities_to_skip),
                execution_time=execution_time,
                successful_city_list=successful_cities,
                failed_city_list=failed_cities,
                skipped_city_list=cities_to_skip
            )
            
            # 8. è®°å½•è®­ç»ƒæŠ¥å‘Š
            self._save_training_report(result)
            
            # 9. è¾“å‡ºæ€»ç»“
            self.logger.info("=" * 60)
            self.logger.info("ğŸ“‹ æ¯æ—¥è®­ç»ƒå®Œæˆæ€»ç»“:")
            self.logger.info(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.1f}ç§’")
            self.logger.info(f"   æ€»åŸå¸‚æ•°: {result.total_cities}")
            self.logger.info(f"   è®­ç»ƒæˆåŠŸ: {result.successful_cities}")
            self.logger.info(f"   è®­ç»ƒå¤±è´¥: {result.failed_cities}")
            self.logger.info(f"   è·³è¿‡è®­ç»ƒ: {result.skipped_cities}")
            
            if result.successful_cities > 0:
                self.logger.info(f"   æˆåŠŸåŸå¸‚: {', '.join(result.successful_city_list)}")
            if result.failed_cities > 0:
                self.logger.info(f"   å¤±è´¥åŸå¸‚: {', '.join(result.failed_city_list)}")
            
            self.logger.info("=" * 60)
            
            return result
            
        except Exception as e:
            end_time = datetime.now()
            self.logger.error(f"æ¯æ—¥è®­ç»ƒæ‰§è¡Œå¤±è´¥: {str(e)}")
            
            # è¿”å›å¤±è´¥ç»“æœ
            return SimpleTrainingResult(
                timestamp=start_time.isoformat(),
                total_cities=len(get_supported_cities()),
                successful_cities=0,
                failed_cities=len(get_supported_cities()),
                skipped_cities=0,
                execution_time=(end_time - start_time).total_seconds(),
                successful_city_list=[],
                failed_city_list=get_supported_cities(),
                skipped_city_list=[]
            )
    
    def _save_training_report(self, result: SimpleTrainingResult):
        """ä¿å­˜è®­ç»ƒæŠ¥å‘Šåˆ°JSONæ–‡ä»¶"""
        try:
            report_file = os.path.join(
                self.log_dir, 
                f"training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            
            report_data = {
                'timestamp': result.timestamp,
                'summary': {
                    'total_cities': result.total_cities,
                    'successful_cities': result.successful_cities,
                    'failed_cities': result.failed_cities,
                    'skipped_cities': result.skipped_cities,
                    'execution_time_seconds': result.execution_time
                },
                'details': {
                    'successful_city_list': result.successful_city_list,
                    'failed_city_list': result.failed_city_list,
                    'skipped_city_list': result.skipped_city_list
                }
            }
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜è®­ç»ƒæŠ¥å‘Šå¤±è´¥: {str(e)}")
    
    def health_check(self) -> Dict[str, bool]:
        """
        ç³»ç»Ÿå¥åº·æ£€æŸ¥
        
        Returns:
            Dict[str, bool]: å„é¡¹æ£€æŸ¥ç»“æœ
        """
        checks = {}
        
        try:
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            cities = get_supported_cities()
            checks['database_connection'] = len(cities) > 0
            
            # æ£€æŸ¥æ¨¡å‹ç›®å½•
            from config.paths import DAILY_MODELS_DIR, LATEST_MODELS_DIR
            checks['model_directories'] = (
                os.path.exists(DAILY_MODELS_DIR) and 
                os.path.exists(LATEST_MODELS_DIR)
            )
            
            # æ£€æŸ¥æ—¥å¿—ç›®å½•
            checks['log_directory'] = os.path.exists(self.log_dir)
            
            # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
            data_available = 0
            for city in cities[:3]:  # åªæ£€æŸ¥å‰3ä¸ªåŸå¸‚
                try:
                    df = load_data_from_mysql(city)
                    if not df.empty:
                        data_available += 1
                except:
                    pass
            checks['data_availability'] = data_available > 0
            
        except Exception as e:
            self.logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
            checks['system_error'] = False
        
        return checks


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        scheduler = SimpleAutoTrainingScheduler()
        
        if command == 'health':
            # å¥åº·æ£€æŸ¥
            checks = scheduler.health_check()
            print("ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥:")
            for check_name, status in checks.items():
                status_icon = "âœ…" if status else "âŒ"
                print(f"  {status_icon} {check_name}: {'é€šè¿‡' if status else 'å¤±è´¥'}")
            
            # å¦‚æœæœ‰æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡ºç ä¸º1
            if not all(checks.values()):
                sys.exit(1)
                
        elif command == 'run':
            # æ‰§è¡Œè®­ç»ƒ
            result = scheduler.run_daily_training()
            
            # å¦‚æœæœ‰å¤±è´¥çš„åŸå¸‚ï¼Œé€€å‡ºç ä¸º1
            if result.failed_cities > 0:
                sys.exit(1)
        
        else:
            print(f"æœªçŸ¥å‘½ä»¤: {command}")
            print("å¯ç”¨å‘½ä»¤: health, run")
            sys.exit(1)
    
    else:
        # é»˜è®¤æ‰§è¡Œè®­ç»ƒ
        scheduler = SimpleAutoTrainingScheduler()
        result = scheduler.run_daily_training()
        
        # å¦‚æœæœ‰å¤±è´¥çš„åŸå¸‚ï¼Œé€€å‡ºç ä¸º1
        if result.failed_cities > 0:
            sys.exit(1)


if __name__ == '__main__':
    main()