#!/usr/bin/env python3
"""
é¢„æµ‹ç¼“å­˜ç®¡ç†è„šæœ¬

æä¾›ç¼“å­˜çš„æŸ¥çœ‹ã€æ¸…ç†ã€æ‰‹åŠ¨ç”Ÿæˆç­‰ç®¡ç†åŠŸèƒ½
"""

import os
import sys
import json
import argparse
from datetime import datetime, timedelta
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from ml.automation.training_scheduler import SimpleAutoTrainingScheduler
from ml.src.control import get_supported_cities


def get_cache_dir() -> str:
    """è·å–ç¼“å­˜ç›®å½•è·¯å¾„"""
    return os.path.join(os.getcwd(), 'data', 'predictions_cache')


def list_cache_files() -> List[Dict]:
    """
    åˆ—å‡ºæ‰€æœ‰ç¼“å­˜æ–‡ä»¶
    
    Returns:
        List[Dict]: ç¼“å­˜æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
    """
    cache_dir = get_cache_dir()
    if not os.path.exists(cache_dir):
        return []
    
    cache_files = []
    for filename in os.listdir(cache_dir):
        if filename.endswith('.json'):
            file_path = os.path.join(cache_dir, filename)
            file_stat = os.stat(file_path)
            
            # å°è¯•è¯»å–æ–‡ä»¶å†…å®¹è·å–å…ƒæ•°æ®
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                
                cache_files.append({
                    'filename': filename,
                    'path': file_path,
                    'size': file_stat.st_size,
                    'modified_time': datetime.fromtimestamp(file_stat.st_mtime),
                    'generated_at': cache_data.get('generated_at'),
                    'cities_count': cache_data.get('cities_count', 0),
                    'date': cache_data.get('date')
                })
            except:
                cache_files.append({
                    'filename': filename,
                    'path': file_path,
                    'size': file_stat.st_size,
                    'modified_time': datetime.fromtimestamp(file_stat.st_mtime),
                    'generated_at': None,
                    'cities_count': 0,
                    'date': None
                })
    
    return sorted(cache_files, key=lambda x: x['modified_time'], reverse=True)


def show_cache_status():
    """æ˜¾ç¤ºç¼“å­˜çŠ¶æ€"""
    print("ğŸ“ é¢„æµ‹ç¼“å­˜çŠ¶æ€æŠ¥å‘Š")
    print("=" * 60)
    
    cache_files = list_cache_files()
    
    if not cache_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç¼“å­˜æ–‡ä»¶")
        print(f"ç¼“å­˜ç›®å½•: {get_cache_dir()}")
        return
    
    print(f"ç¼“å­˜ç›®å½•: {get_cache_dir()}")
    print(f"ç¼“å­˜æ–‡ä»¶æ•°: {len(cache_files)}")
    print()
    
    # æ˜¾ç¤ºæœ€æ–°ç¼“å­˜ä¿¡æ¯
    latest_cache = None
    for cache_file in cache_files:
        if cache_file['filename'] == 'latest_predictions.json':
            latest_cache = cache_file
            break
    
    if latest_cache:
        print("ğŸ”® æœ€æ–°ç¼“å­˜:")
        print(f"  æ–‡ä»¶: {latest_cache['filename']}")
        print(f"  ç”Ÿæˆæ—¶é—´: {latest_cache['generated_at'] or 'æœªçŸ¥'}")
        print(f"  åŸå¸‚æ•°é‡: {latest_cache['cities_count']}")
        print(f"  æ–‡ä»¶å¤§å°: {latest_cache['size']:,} å­—èŠ‚")
        print()
    
    # æ˜¾ç¤ºå†å²ç¼“å­˜æ–‡ä»¶
    daily_caches = [f for f in cache_files if f['filename'].startswith('daily_predictions_')]
    if daily_caches:
        print("ğŸ“… å†å²ç¼“å­˜æ–‡ä»¶:")
        for cache_file in daily_caches[:5]:  # åªæ˜¾ç¤ºæœ€è¿‘5ä¸ª
            age = datetime.now() - cache_file['modified_time']
            print(f"  {cache_file['filename']} ({cache_file['cities_count']}ä¸ªåŸå¸‚, {age.days}å¤©å‰)")
        
        if len(daily_caches) > 5:
            print(f"  ... è¿˜æœ‰ {len(daily_caches) - 5} ä¸ªæ–‡ä»¶")
    
    print()


def view_cache_content(date_str: str = None):
    """
    æŸ¥çœ‹ç¼“å­˜å†…å®¹
    
    Args:
        date_str (str): æ—¥æœŸå­—ç¬¦ä¸² (YYYYMMDD)ï¼Œé»˜è®¤æŸ¥çœ‹æœ€æ–°ç¼“å­˜
    """
    scheduler = SimpleAutoTrainingScheduler()
    cache_data = scheduler.load_predictions_cache(date_str)
    
    if not cache_data:
        print(f"âŒ æœªæ‰¾åˆ°ç¼“å­˜æ•°æ® (æ—¥æœŸ: {date_str or 'æœ€æ–°'})")
        return
    
    print(f"ğŸ”® ç¼“å­˜å†…å®¹è¯¦æƒ… (æ—¥æœŸ: {cache_data.get('date', 'æœªçŸ¥')})")
    print("=" * 60)
    print(f"ç”Ÿæˆæ—¶é—´: {cache_data.get('generated_at', 'æœªçŸ¥')}")
    print(f"åŸå¸‚æ•°é‡: {cache_data.get('cities_count', 0)}")
    print()
    
    predictions = cache_data.get('predictions', {})
    if not predictions:
        print("âŒ ç¼“å­˜ä¸­æ— é¢„æµ‹æ•°æ®")
        return
    
    print("åŸå¸‚é¢„æµ‹æ•°æ®:")
    for city, data in predictions.items():
        current_value = data.get('currentValue', 0)
        avg_value = data.get('avgValue', 0)
        update_time = data.get('updateTime', 'æœªçŸ¥')
        cached = data.get('cached', False)
        
        print(f"  {city:12} | å½“å‰: {current_value:6.1f} | å¹³å‡: {avg_value:6.1f} | æ›´æ–°: {update_time} | ç¼“å­˜: {'æ˜¯' if cached else 'å¦'}")


def cleanup_old_cache(days_to_keep: int = 7):
    """
    æ¸…ç†æ—§çš„ç¼“å­˜æ–‡ä»¶
    
    Args:
        days_to_keep (int): ä¿ç•™çš„å¤©æ•°ï¼Œé»˜è®¤7å¤©
    """
    print(f"ğŸ§¹ æ¸…ç† {days_to_keep} å¤©å‰çš„ç¼“å­˜æ–‡ä»¶...")
    
    cache_files = list_cache_files()
    cutoff_time = datetime.now() - timedelta(days=days_to_keep)
    
    removed_count = 0
    for cache_file in cache_files:
        # è·³è¿‡latest_predictions.json
        if cache_file['filename'] == 'latest_predictions.json':
            continue
        
        if cache_file['modified_time'] < cutoff_time:
            try:
                os.remove(cache_file['path'])
                removed_count += 1
                print(f"  âœ… åˆ é™¤: {cache_file['filename']}")
            except Exception as e:
                print(f"  âŒ åˆ é™¤å¤±è´¥: {cache_file['filename']} - {e}")
    
    if removed_count > 0:
        print(f"ğŸ—‘ï¸  å·²æ¸…ç† {removed_count} ä¸ªç¼“å­˜æ–‡ä»¶")
    else:
        print("â„¹ï¸  æ²¡æœ‰éœ€è¦æ¸…ç†çš„ç¼“å­˜æ–‡ä»¶")


def generate_cache_manually(cities: List[str] = None):
    """
    æ‰‹åŠ¨ç”Ÿæˆé¢„æµ‹ç¼“å­˜
    
    Args:
        cities (List[str]): è¦ç”Ÿæˆç¼“å­˜çš„åŸå¸‚åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰åŸå¸‚
    """
    if cities is None:
        cities = get_supported_cities()
    
    print(f"ğŸ”® æ‰‹åŠ¨ç”Ÿæˆé¢„æµ‹ç¼“å­˜ ({len(cities)} ä¸ªåŸå¸‚)...")
    
    scheduler = SimpleAutoTrainingScheduler()
    result = scheduler._precompute_daily_predictions(cities)
    
    print(f"ç”Ÿæˆå®Œæˆ: æˆåŠŸ {result['successful']} ä¸ªåŸå¸‚, å¤±è´¥ {result['failed']} ä¸ªåŸå¸‚")
    
    if result['successful'] > 0:
        print("âœ… ç¼“å­˜ç”ŸæˆæˆåŠŸï¼Œå¯é€šè¿‡ API è®¿é—®é¢„æµ‹æ•°æ®")
    
    if result['failed'] > 0:
        print("âš ï¸  éƒ¨åˆ†åŸå¸‚ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é¢„æµ‹ç¼“å­˜ç®¡ç†å·¥å…·')
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # status å‘½ä»¤
    subparsers.add_parser('status', help='æ˜¾ç¤ºç¼“å­˜çŠ¶æ€')
    
    # view å‘½ä»¤
    view_parser = subparsers.add_parser('view', help='æŸ¥çœ‹ç¼“å­˜å†…å®¹')
    view_parser.add_argument('--date', help='æ—¥æœŸ (YYYYMMDD)ï¼Œé»˜è®¤æŸ¥çœ‹æœ€æ–°ç¼“å­˜')
    
    # cleanup å‘½ä»¤
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§ç¼“å­˜æ–‡ä»¶')
    cleanup_parser.add_argument('--days', type=int, default=7, help='ä¿ç•™å¤©æ•° (é»˜è®¤7å¤©)')
    
    # generate å‘½ä»¤
    generate_parser = subparsers.add_parser('generate', help='æ‰‹åŠ¨ç”Ÿæˆç¼“å­˜')
    generate_parser.add_argument('--cities', nargs='+', help='æŒ‡å®šåŸå¸‚åˆ—è¡¨ (é»˜è®¤æ‰€æœ‰åŸå¸‚)')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        if args.command == 'status':
            show_cache_status()
        
        elif args.command == 'view':
            view_cache_content(args.date)
        
        elif args.command == 'cleanup':
            cleanup_old_cache(args.days)
        
        elif args.command == 'generate':
            generate_cache_manually(args.cities)
        
    except KeyboardInterrupt:
        print("\næ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()